---
title: Kruskal-Wallis Test
tags: Statistics, HypothesisTesting, NonParametric
---

# Kruskal-Wallis Test

The Kruskal-Wallis test is like pooling all the students from three different gym classes into a massive, single line from shortest to tallest, and then checking if everyone from Ms. Smith's class just happens to be crammed near the very tall end of the line.

**The Kruskal-Wallis H Test** is a non-parametric statistical test that extends the [[mann-whitney-u|Mann-Whitney U Test]] to determine whether there are statistically significant differences between three or more independent groups.

Imagine you are trying to test the exact same tire fuel efficiency concept used in [[anova|ANOVA]] (Brand X vs. Brand Y vs. Brand Z). However, your MPG data is completely chaotic. There are massive outliers, the data doesnâ€™t form a nice, predictable bell curve, or maybe your data isn't even continuous (e.g., you are just asking people to rank the tires from 1-10 on a satisfaction survey). 

Because [[anova|ANOVA]] relies heavily on averages, inserting severe outliers or non-numerical rankings ruins its mathematical assumptions. Kruskal-Wallis ignores the raw values altogether and replaces them with **ranks**. It takes every single tire test result across all three brands, sorts them from 1st place to worst place, and then calculates the *average rank* belonging to each specific brand. If Brand X's average rank is significantly higher than Brand Z's, the test flags that at least one group mathematically dominates the others.

## Key Features

*   **Distribution-Free:** Because it abandons raw numbers for mere ranks, it genuinely does not matter if your data is severely skewed or un-normally distributed.
*   **The "Omnibus" Test:** Like [[anova|ANOVA]], Kruskal-Wallis only tells you that *at least one* group is significantly different from the others. It does *not* tell you which specific one it is.
*   **Post-Hoc Testing:** To figure out which specific groups are different, you must run secondary tests (often a series of [[mann-whitney-u|Mann-Whitney U Tests]] with a strict mathematical penalty called a Bonferroni correction to prevent false positives).

## FAQs

*1. Why not just always use Kruskal-Wallis instead of [[anova|ANOVA]]?*
If your data perfectly fits a standard bell curve, [[anova|ANOVA]] is mathematically more powerful and precise because it uses the raw, nuanced numbers rather than stripping them down to blunt ranks. Kruskal-Wallis is the "safe" backup plan.

*2. What happens if I use Kruskal-Wallis on just two groups?*
If you only have two groups instead of three, the math perfectly collapses down and becomes the exact same thing as a [[mann-whitney-u|Mann-Whitney U Test]].

### Further Reading

*   **Related Concept:** *[[anova|ANOVA (Analysis of Variance)]]* (The standard parametric version of this test used for continuous, normally distributed data).
*   **Related Concept:** *[[mann-whitney-u|Mann-Whitney U Test]]* (The exact equivalent of this test when you only have two groups).
